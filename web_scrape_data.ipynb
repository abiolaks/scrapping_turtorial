{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1d0a246e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scraping page 1...\n",
      "Scraping page 2...\n",
      "Scraping page 3...\n",
      "Scraping page 4...\n",
      "Scraping complete! Data saved to books_detailed_dataset.csv\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "import time\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "BASE_URL = \"http://books.toscrape.com/catalogue/page-{}.html\"\n",
    "BASE_SITE = \"http://books.toscrape.com/catalogue/\"\n",
    "\n",
    "books = []\n",
    "\n",
    "for page in range(1,5):  # Loop through all 50 pages\n",
    "    print(f\"Scraping page {page}...\")\n",
    "    url = BASE_URL.format(page)\n",
    "    response = requests.get(url)\n",
    "    soup = BeautifulSoup(response.text, 'html.parser')\n",
    "\n",
    "    for book in soup.find_all(\"article\", class_=\"product_pod\"):\n",
    "        # Basic info from listing page\n",
    "        title = book.h3.a[\"title\"]\n",
    "        price = book.find(\"p\", class_=\"price_color\").text.strip()\n",
    "        rating = book.p[\"class\"][1]  \n",
    "        \n",
    "        # Book detail page link\n",
    "        book_url = BASE_SITE + book.h3.a[\"href\"].replace('../../../', '')\n",
    "        book_resp = requests.get(book_url)\n",
    "        book_soup = BeautifulSoup(book_resp.text, 'html.parser')\n",
    "\n",
    "        # Category\n",
    "        category = book_soup.find(\"ul\", class_=\"breadcrumb\").find_all(\"li\")[2].text.strip()\n",
    "\n",
    "        # Product description\n",
    "        desc_tag = book_soup.find(\"div\", id=\"product_description\")\n",
    "        description = desc_tag.find_next_sibling(\"p\").text.strip() if desc_tag else \"\"\n",
    "\n",
    "        # Table info (UPC, stock)\n",
    "        table_rows = book_soup.find(\"table\", class_=\"table table-striped\").find_all(\"tr\")\n",
    "        upc = table_rows[0].find(\"td\").text.strip()\n",
    "        stock_text = table_rows[5].find(\"td\").text.strip()\n",
    "        \n",
    "        # Extract stock number (e.g., \"In stock (22 available)\")\n",
    "        stock_count = ''.join([c for c in stock_text if c.isdigit()])\n",
    "\n",
    "        # Availability (from list page, cleaned)\n",
    "        availability = book.find(\"p\", class_=\"instock availability\").text.strip()\n",
    "\n",
    "        books.append({\n",
    "            \"Title\": title,\n",
    "            \"Price\": price,\n",
    "            \"Availability\": availability,\n",
    "            \"Stock Count\": stock_count,\n",
    "            \"Rating\": rating,\n",
    "            \"Category\": category,\n",
    "            \"UPC\": upc,\n",
    "            \"Description\": description\n",
    "        })\n",
    "\n",
    "        time.sleep(0.2)  # short delay for detail page requests\n",
    "\n",
    "    time.sleep(1)  # delay for page requests\n",
    "\n",
    "# Save to CSV\n",
    "df = pd.DataFrame(books)\n",
    "df.to_csv(\"books_detailed_dataset.csv\", index=False, encoding=\"utf-8\")\n",
    "print(\"Scraping complete! Data saved to books_detailed_dataset.csv\")\n",
    "\n",
    "# preprocessing da\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e4ac841",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
